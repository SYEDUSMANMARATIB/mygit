{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Muhammad Usman Maratib 19i-1791"],"metadata":{"id":"htSAS27OTUuN"}},{"cell_type":"markdown","source":["classes Discriminator and Generator   LAB#4\n"],"metadata":{"id":"bpdGlGMhTIkL"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qicGQSBUP0nK","outputId":"2fc9a266-fc8f-4ee4-f4a9-1582b5f04651"},"outputs":[{"output_type":"stream","name":"stdout","text":["Generator(\n","  (layers): Sequential(\n","    (0): Conv2d(1, 128, kernel_size=(4, 4), stride=(1, 1))\n","    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (7): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): Conv2d(512, 1024, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (10): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(1024, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (13): Tanh()\n","  )\n",")\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","class Generator(nn.Module):\n","    def __init__(self, input_channels=1, output_channels=1, input_size=64):\n","        super(Generator, self).__init__()\n","\n","        # Define a list of layer blocks using nn.Sequential\n","        self.layers = nn.Sequential(\n","            nn.Conv2d(input_channels, 128, kernel_size=4, stride=1, padding=0),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(1024),\n","            nn.ReLU(inplace=True),\n","\n","            nn.Conv2d(1024, output_channels, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh()\n","        )\n","\n","        # Storing  for validation in forward method\n","        self.input_size = input_size\n","\n","    def forward(self, x):\n","        #input dimensions\n","        assert x.size() == (x.size(0), self.layers[0].in_channels, self.input_size, self.input_size), \\\n","            f\"Input image dimension should be (batch_size, {self.layers[0].in_channels}, {self.input_size}, {self.input_size})\"\n","\n","        # Forward pass through layers\n","        x = self.layers(x)\n","\n","        return x\n","\n","generator = Generator()\n","print(generator)\n"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, input_channels=1, output_channels=1, output_size=64):\n","        super(Discriminator, self).__init__()\n","\n","        #layer blocks using nn.Sequential\n","        self.layers = nn.Sequential(\n","            nn.ConvTranspose2d(100, 1024, kernel_size=4, stride=1, padding=0),\n","            nn.BatchNorm2d(1024),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(1024, 512, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(256),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n","            nn.BatchNorm2d(128),\n","            nn.ReLU(inplace=True),\n","\n","            nn.ConvTranspose2d(128, output_channels, kernel_size=4, stride=2, padding=1),\n","            nn.Tanh()\n","        )\n","\n","        #  validation in forward method\n","        self.output_size = output_size\n","\n","    def forward(self, x):\n","        # Check input dimensions\n","        assert x.size() == (x.size(0), self.layers[0].in_channels, self.output_size, self.output_size), \\\n","            f\"Input image dimension should be (batch_size, {self.layers[0].in_channels}, {self.output_size}, {self.output_size})\"\n","\n","\n","        x = self.layers(x)\n","\n","        return x\n","\n","# Instantiate the Discriminator with default values\n","discriminator = Discriminator()\n","print(discriminator)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D_RIs37FS2Aa","outputId":"b37e8094-8be6-4bec-b5a3-dcb17ab9c4bf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Discriminator(\n","  (layers): Sequential(\n","    (0): ConvTranspose2d(100, 1024, kernel_size=(4, 4), stride=(1, 1))\n","    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): ReLU(inplace=True)\n","    (3): ConvTranspose2d(1024, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): ReLU(inplace=True)\n","    (6): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): ReLU(inplace=True)\n","    (9): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (10): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): ReLU(inplace=True)\n","    (12): ConvTranspose2d(128, 1, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n","    (13): Tanh()\n","  )\n",")\n"]}]}]}