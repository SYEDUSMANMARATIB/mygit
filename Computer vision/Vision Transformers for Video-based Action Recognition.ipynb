{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport os\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\nwith open('/kaggle/input/assignment/kinetics_train.json', 'r') as f:\n    data = json.load(f)\n\n\nvideo_urls = [entry['url'] for entry in data.values()]\nlabels = [entry['annotations']['label'] for entry in data.values()]","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:11.331444Z","iopub.execute_input":"2023-10-19T13:56:11.331693Z","iopub.status.idle":"2023-10-19T13:56:11.935265Z","shell.execute_reply.started":"2023-10-19T13:56:11.331671Z","shell.execute_reply":"2023-10-19T13:56:11.934546Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install pytube","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:11.936715Z","iopub.execute_input":"2023-10-19T13:56:11.936963Z","iopub.status.idle":"2023-10-19T13:56:21.694761Z","shell.execute_reply.started":"2023-10-19T13:56:11.936942Z","shell.execute_reply":"2023-10-19T13:56:21.693879Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pytube\n  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: pytube\nSuccessfully installed pytube-15.0.0\n","output_type":"stream"}]},{"cell_type":"code","source":"from pytube import YouTube\n\ndef download_video(url, output_path):\n    yt = YouTube(url)\n    stream = yt.streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\").desc().first()\n    stream.download(output_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:21.696369Z","iopub.execute_input":"2023-10-19T13:56:21.696716Z","iopub.status.idle":"2023-10-19T13:56:21.717991Z","shell.execute_reply.started":"2023-10-19T13:56:21.696683Z","shell.execute_reply":"2023-10-19T13:56:21.717079Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from pytube.exceptions import AgeRestrictedError, VideoUnavailable\nimport os\n\ndef safe_download_video(url, output_path):\n    try:\n        yt = YouTube(url)\n        stream = yt.streams.filter(progressive=True, file_extension=\"mp4\").order_by(\"resolution\").desc().first()\n        if stream:\n            stream.download(output_path)\n        else:\n            print(f\"No suitable stream found for video: {url}\")\n    except AgeRestrictedError:\n        print(f\"Skipping age-restricted video: {url}\")\n    except KeyError:\n        print(f\"Skipping video due to missing metadata: {url}\")\n    except VideoUnavailable:\n        print(f\"Skipping unavailable video: {url}\")\n\nvideo_download_dir = '/kaggle/working/videos' \n\n# Select only the first 10 videos\nfor idx, url in enumerate(video_urls[:10]):\n    video_path = os.path.join(video_download_dir, f\"{idx}.mp4\")\n    safe_download_video(url, video_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:21.720349Z","iopub.execute_input":"2023-10-19T13:56:21.720661Z","iopub.status.idle":"2023-10-19T13:56:36.398093Z","shell.execute_reply.started":"2023-10-19T13:56:21.720630Z","shell.execute_reply":"2023-10-19T13:56:36.397111Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Skipping age-restricted video: https://www.youtube.com/watch?v=w0kkkBCE028\nSkipping video due to missing metadata: https://www.youtube.com/watch?v=X3L23IqtqWw\nSkipping age-restricted video: https://www.youtube.com/watch?v=KgWWZyhJRSw\nSkipping video due to missing metadata: https://www.youtube.com/watch?v=s65GEgCm4JA\nSkipping unavailable video: https://www.youtube.com/watch?v=rBxLZWb6Df4\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install imageio[ffmpeg]\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:36.399126Z","iopub.execute_input":"2023-10-19T13:56:36.399414Z","iopub.status.idle":"2023-10-19T13:56:45.816685Z","shell.execute_reply.started":"2023-10-19T13:56:36.399391Z","shell.execute_reply":"2023-10-19T13:56:45.815612Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: imageio[ffmpeg] in /opt/conda/lib/python3.10/site-packages (2.31.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from imageio[ffmpeg]) (1.23.5)\nRequirement already satisfied: pillow>=8.3.2 in /opt/conda/lib/python3.10/site-packages (from imageio[ffmpeg]) (9.5.0)\nCollecting imageio-ffmpeg (from imageio[ffmpeg])\n  Downloading imageio_ffmpeg-0.4.9-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from imageio[ffmpeg]) (5.9.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from imageio-ffmpeg->imageio[ffmpeg]) (68.0.0)\nInstalling collected packages: imageio-ffmpeg\nSuccessfully installed imageio-ffmpeg-0.4.9\n","output_type":"stream"}]},{"cell_type":"code","source":"# import shutil\n\n# directory_to_remove = '/kaggle/working/frames'\n\n# shutil.rmtree(directory_to_remove)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:45.818083Z","iopub.execute_input":"2023-10-19T13:56:45.818368Z","iopub.status.idle":"2023-10-19T13:56:45.822560Z","shell.execute_reply.started":"2023-10-19T13:56:45.818343Z","shell.execute_reply":"2023-10-19T13:56:45.821653Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\n\ndef extract_middle_frame(video_path, output_path):\n    cap = cv2.VideoCapture(video_path)\n    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n    cap.set(cv2.CAP_PROP_POS_FRAMES, total_frames // 2)\n    ret, frame = cap.read()\n    if ret:\n        cv2.imwrite(output_path, frame, [cv2.IMWRITE_JPEG_QUALITY, 100])  # Save as JPG with maximum quality\n    cap.release()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:45.823709Z","iopub.execute_input":"2023-10-19T13:56:45.824011Z","iopub.status.idle":"2023-10-19T13:56:46.029875Z","shell.execute_reply.started":"2023-10-19T13:56:45.823983Z","shell.execute_reply":"2023-10-19T13:56:46.028909Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport os\n\nvideo_dir = '/kaggle/working/videos' \nframe_dir = '/kaggle/working/frames'  \n\nfor class_label in os.listdir(video_dir):\n    class_path = os.path.join(video_dir, class_label)\n    frame_class_path = os.path.join(frame_dir, class_label)\n    os.makedirs(frame_class_path, exist_ok=True)\n    \n    for video_file in os.listdir(class_path):\n        video_path = os.path.join(class_path, video_file)\n        frame_path = os.path.join(frame_class_path, video_file.replace('.mp4', '.jpg'))\n        extract_middle_frame(video_path, frame_path)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.030985Z","iopub.execute_input":"2023-10-19T13:56:46.031273Z","iopub.status.idle":"2023-10-19T13:56:46.409838Z","shell.execute_reply.started":"2023-10-19T13:56:46.031250Z","shell.execute_reply":"2023-10-19T13:56:46.408926Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"os.listdir('/kaggle/working/frames/')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.410900Z","iopub.execute_input":"2023-10-19T13:56:46.411163Z","iopub.status.idle":"2023-10-19T13:56:46.418318Z","shell.execute_reply.started":"2023-10-19T13:56:46.411142Z","shell.execute_reply":"2023-10-19T13:56:46.417582Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['0.mp4', '4.mp4', '3.mp4', '8.mp4', '2.mp4']"},"metadata":{}}]},{"cell_type":"code","source":"os.listdir('/kaggle/working/videos')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.421926Z","iopub.execute_input":"2023-10-19T13:56:46.422163Z","iopub.status.idle":"2023-10-19T13:56:46.431180Z","shell.execute_reply.started":"2023-10-19T13:56:46.422143Z","shell.execute_reply":"2023-10-19T13:56:46.430446Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"['0.mp4', '4.mp4', '3.mp4', '8.mp4', '2.mp4']"},"metadata":{}}]},{"cell_type":"code","source":"video_filenames = os.listdir('/kaggle/working/videos')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.432018Z","iopub.execute_input":"2023-10-19T13:56:46.432557Z","iopub.status.idle":"2023-10-19T13:56:46.442268Z","shell.execute_reply.started":"2023-10-19T13:56:46.432535Z","shell.execute_reply":"2023-10-19T13:56:46.441559Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"video_filenames","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.443212Z","iopub.execute_input":"2023-10-19T13:56:46.443434Z","iopub.status.idle":"2023-10-19T13:56:46.454181Z","shell.execute_reply.started":"2023-10-19T13:56:46.443415Z","shell.execute_reply":"2023-10-19T13:56:46.453539Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"['0.mp4', '4.mp4', '3.mp4', '8.mp4', '2.mp4']"},"metadata":{}}]},{"cell_type":"code","source":"video_filenames","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.455035Z","iopub.execute_input":"2023-10-19T13:56:46.455334Z","iopub.status.idle":"2023-10-19T13:56:46.467008Z","shell.execute_reply.started":"2023-10-19T13:56:46.455313Z","shell.execute_reply":"2023-10-19T13:56:46.466236Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['0.mp4', '4.mp4', '3.mp4', '8.mp4', '2.mp4']"},"metadata":{}}]},{"cell_type":"code","source":"\nselected_labels = [labels[video_filenames.index(filename)] for filename in video_filenames]\n\nprint(selected_labels)\n\nprint(len(selected_labels))\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.467958Z","iopub.execute_input":"2023-10-19T13:56:46.468237Z","iopub.status.idle":"2023-10-19T13:56:46.479036Z","shell.execute_reply.started":"2023-10-19T13:56:46.468211Z","shell.execute_reply":"2023-10-19T13:56:46.478313Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"['dancing macarena', 'somersaulting', 'shoveling snow', 'deadlifting', 'playing violin']\n5\n","output_type":"stream"}]},{"cell_type":"code","source":"os.listdir('/kaggle/working/frames')","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.479991Z","iopub.execute_input":"2023-10-19T13:56:46.480293Z","iopub.status.idle":"2023-10-19T13:56:46.492737Z","shell.execute_reply.started":"2023-10-19T13:56:46.480264Z","shell.execute_reply":"2023-10-19T13:56:46.491904Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"['0.mp4', '4.mp4', '3.mp4', '8.mp4', '2.mp4']"},"metadata":{}}]},{"cell_type":"code","source":"len(os.listdir('/kaggle/working/frames/'))","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.493854Z","iopub.execute_input":"2023-10-19T13:56:46.494111Z","iopub.status.idle":"2023-10-19T13:56:46.504932Z","shell.execute_reply.started":"2023-10-19T13:56:46.494090Z","shell.execute_reply":"2023-10-19T13:56:46.503996Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"5"},"metadata":{}}]},{"cell_type":"code","source":"frame_dir = '/kaggle/working/frames'\nvideo_labels = {  \n    '3.mp4': 'label1',\n    '0.mp4': 'label2',\n    '2.mp4': 'label3',\n    '8.mp4': 'label4',\n    '4.mp4': 'label5',\n}\n\nimages = []\n\nimport os\nimport shutil\n\nfor video_file, label in video_labels.items():\n    video_folder_path = os.path.join(frame_dir, video_file)\n    if os.path.isdir(video_folder_path):\n        jpg_files = [f for f in os.listdir(video_folder_path) if f.endswith('.jpg')]\n        \n        # Define the new directory path\n        new_dir = os.path.join('/kaggle/working/images')  # Replace 'path_to_new_directory' with the actual path\n        \n        # Create the new directory if it doesn't exist\n        if not os.path.exists(new_dir):\n            os.makedirs(new_dir)\n        \n        # Copy jpg_files to the new directory\n        for jpg_file in jpg_files:\n            source_path = os.path.join(video_folder_path, jpg_file)\n            destination_path = os.path.join(new_dir, jpg_file)\n            shutil.copy(source_path, destination_path)\n        \n        print(jpg_files)\n\n                    ","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.505843Z","iopub.execute_input":"2023-10-19T13:56:46.506123Z","iopub.status.idle":"2023-10-19T13:56:46.519994Z","shell.execute_reply.started":"2023-10-19T13:56:46.506098Z","shell.execute_reply":"2023-10-19T13:56:46.519237Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"['Deadlift training 520x2 545x3+ speed work.jpg']\n['Dancing Divas - Macarena Warmup.jpg']\n['Shoveling Snow!.jpg']\n['standing front dumbbell raise.jpg']\n['Carlo Cantini Play Violin 2.jpg']\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nfrom PIL import Image\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\n\nclass CustomDataset(Dataset):\n    def __init__(self, root_dir, labels, transform=None):\n        self.root_dir = root_dir\n        self.labels = labels\n        self.transform = transform\n        self.image_files = list(labels.keys())  # List of image filenames\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        filename = self.image_files[idx]  # Get the filename based on the index\n        img_name = os.path.join(self.root_dir, filename)\n        \n        if not os.path.exists(img_name):\n            raise ValueError(f\"Image {img_name} not found.\")\n        \n        image = Image.open(img_name)\n        label = self.labels[filename] \n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label\n\nframe_dir = '/kaggle/working/images'  \nlabels = {\n    'standing front dumbbell raise.jpg': 'dumbell_raise',\n    'Dancing Divas - Macarena Warmup.jpg': 'Dancing_Macarena',\n    'Shoveling Snow!.jpg': 'Shoveling_snow',\n    'Carlo Cantini Play Violin 2.jpg': 'Playing_violin',\n    'Deadlift training 520x2 545x3+ speed work.jpg': 'Deadlift'\n}\nlabels = labels\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])\n\ncustom_dataset = CustomDataset(root_dir=frame_dir, labels=labels, transform=transform)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:46.520935Z","iopub.execute_input":"2023-10-19T13:56:46.521169Z","iopub.status.idle":"2023-10-19T13:56:48.086367Z","shell.execute_reply.started":"2023-10-19T13:56:46.521148Z","shell.execute_reply":"2023-10-19T13:56:48.085418Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"labels","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:48.087438Z","iopub.execute_input":"2023-10-19T13:56:48.087788Z","iopub.status.idle":"2023-10-19T13:56:48.093219Z","shell.execute_reply.started":"2023-10-19T13:56:48.087765Z","shell.execute_reply":"2023-10-19T13:56:48.092373Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"{'standing front dumbbell raise.jpg': 'dumbell_raise',\n 'Dancing Divas - Macarena Warmup.jpg': 'Dancing_Macarena',\n 'Shoveling Snow!.jpg': 'Shoveling_snow',\n 'Carlo Cantini Play Violin 2.jpg': 'Playing_violin',\n 'Deadlift training 520x2 545x3+ speed work.jpg': 'Deadlift'}"},"metadata":{}}]},{"cell_type":"code","source":"for i in custom_dataset:\n    print(i)","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:48.094321Z","iopub.execute_input":"2023-10-19T13:56:48.094871Z","iopub.status.idle":"2023-10-19T13:56:48.249346Z","shell.execute_reply.started":"2023-10-19T13:56:48.094841Z","shell.execute_reply":"2023-10-19T13:56:48.248436Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"(tensor([[[0.2275, 0.2275, 0.2314,  ..., 0.3255, 0.3020, 0.2980],\n         [0.2275, 0.2275, 0.2314,  ..., 0.2706, 0.2510, 0.2471],\n         [0.2275, 0.2275, 0.2314,  ..., 0.2000, 0.1961, 0.1882],\n         ...,\n         [0.0471, 0.0588, 0.0902,  ..., 0.5020, 0.5020, 0.5020],\n         [0.0549, 0.0549, 0.0745,  ..., 0.5020, 0.5020, 0.5020],\n         [0.0549, 0.0588, 0.0627,  ..., 0.5020, 0.5020, 0.5020]],\n\n        [[0.1843, 0.1843, 0.1882,  ..., 0.4667, 0.4431, 0.4392],\n         [0.1843, 0.1843, 0.1882,  ..., 0.4078, 0.3922, 0.3882],\n         [0.1843, 0.1843, 0.1882,  ..., 0.3333, 0.3294, 0.3216],\n         ...,\n         [0.0431, 0.0549, 0.0824,  ..., 0.4863, 0.4863, 0.4863],\n         [0.0510, 0.0510, 0.0667,  ..., 0.4863, 0.4863, 0.4863],\n         [0.0510, 0.0549, 0.0588,  ..., 0.4863, 0.4863, 0.4863]],\n\n        [[0.1608, 0.1608, 0.1647,  ..., 0.4549, 0.4353, 0.4235],\n         [0.1608, 0.1608, 0.1647,  ..., 0.3922, 0.3765, 0.3647],\n         [0.1608, 0.1608, 0.1647,  ..., 0.3098, 0.3059, 0.2941],\n         ...,\n         [0.0275, 0.0392, 0.0706,  ..., 0.3804, 0.3804, 0.3804],\n         [0.0353, 0.0353, 0.0549,  ..., 0.3804, 0.3804, 0.3804],\n         [0.0353, 0.0392, 0.0431,  ..., 0.3804, 0.3804, 0.3804]]]), 'dumbell_raise')\n(tensor([[[0.4863, 0.4902, 0.4980,  ..., 0.5529, 0.5333, 0.5216],\n         [0.4902, 0.4941, 0.4980,  ..., 0.5451, 0.5216, 0.5137],\n         [0.4902, 0.4941, 0.4980,  ..., 0.5373, 0.5176, 0.5059],\n         ...,\n         [0.6039, 0.6039, 0.6118,  ..., 0.3647, 0.3569, 0.3569],\n         [0.6039, 0.6078, 0.6157,  ..., 0.3647, 0.3569, 0.3569],\n         [0.6078, 0.6078, 0.6157,  ..., 0.3647, 0.3569, 0.3569]],\n\n        [[0.5216, 0.5255, 0.5255,  ..., 0.6431, 0.6235, 0.6118],\n         [0.5255, 0.5294, 0.5255,  ..., 0.6353, 0.6118, 0.6039],\n         [0.5255, 0.5294, 0.5294,  ..., 0.6275, 0.6078, 0.5961],\n         ...,\n         [0.5373, 0.5373, 0.5373,  ..., 0.2941, 0.2863, 0.2863],\n         [0.5373, 0.5412, 0.5412,  ..., 0.2941, 0.2863, 0.2863],\n         [0.5412, 0.5412, 0.5412,  ..., 0.2941, 0.2863, 0.2863]],\n\n        [[0.4549, 0.4588, 0.4667,  ..., 0.5647, 0.5451, 0.5333],\n         [0.4588, 0.4627, 0.4667,  ..., 0.5569, 0.5333, 0.5255],\n         [0.4588, 0.4627, 0.4667,  ..., 0.5490, 0.5294, 0.5176],\n         ...,\n         [0.3647, 0.3647, 0.3686,  ..., 0.1451, 0.1373, 0.1373],\n         [0.3647, 0.3686, 0.3725,  ..., 0.1451, 0.1373, 0.1373],\n         [0.3686, 0.3686, 0.3725,  ..., 0.1451, 0.1373, 0.1373]]]), 'Dancing_Macarena')\n(tensor([[[0.7529, 0.7608, 0.7725,  ..., 0.9098, 0.9059, 0.9020],\n         [0.9412, 0.9451, 0.9373,  ..., 0.9098, 0.9059, 0.9020],\n         [0.9608, 0.9647, 0.9686,  ..., 0.9098, 0.9059, 0.9020],\n         ...,\n         [0.9176, 0.9176, 0.9176,  ..., 0.8902, 0.8902, 0.8941],\n         [0.9333, 0.9333, 0.9333,  ..., 0.8706, 0.8784, 0.8863],\n         [0.9412, 0.9412, 0.9412,  ..., 0.8510, 0.8627, 0.8745]],\n\n        [[0.7451, 0.7529, 0.7647,  ..., 0.9020, 0.8980, 0.8941],\n         [0.9333, 0.9373, 0.9294,  ..., 0.9020, 0.8980, 0.8941],\n         [0.9529, 0.9569, 0.9608,  ..., 0.9020, 0.8980, 0.8941],\n         ...,\n         [0.9137, 0.9137, 0.9137,  ..., 0.8980, 0.8980, 0.9020],\n         [0.9294, 0.9294, 0.9294,  ..., 0.8784, 0.8863, 0.8941],\n         [0.9373, 0.9373, 0.9373,  ..., 0.8588, 0.8706, 0.8824]],\n\n        [[0.7490, 0.7569, 0.7686,  ..., 0.9137, 0.9098, 0.9059],\n         [0.9373, 0.9412, 0.9333,  ..., 0.9137, 0.9098, 0.9059],\n         [0.9569, 0.9608, 0.9647,  ..., 0.9137, 0.9098, 0.9059],\n         ...,\n         [0.9059, 0.9059, 0.9059,  ..., 0.8863, 0.8863, 0.8902],\n         [0.9216, 0.9216, 0.9216,  ..., 0.8667, 0.8745, 0.8824],\n         [0.9294, 0.9294, 0.9294,  ..., 0.8471, 0.8588, 0.8706]]]), 'Shoveling_snow')\n(tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0078, 0.0118, 0.0118,  ..., 0.0235, 0.0235, 0.0235],\n         ...,\n         [0.0549, 0.0588, 0.0745,  ..., 0.0392, 0.0392, 0.0392],\n         [0.0039, 0.0078, 0.0078,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0196, 0.0196, 0.0196,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0078, 0.0118, 0.0118,  ..., 0.0235, 0.0235, 0.0235],\n         ...,\n         [0.0549, 0.0588, 0.0745,  ..., 0.0353, 0.0353, 0.0353],\n         [0.0039, 0.0078, 0.0078,  ..., 0.0039, 0.0039, 0.0039],\n         [0.0196, 0.0196, 0.0196,  ..., 0.0000, 0.0000, 0.0000]],\n\n        [[0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0078, 0.0078],\n         [0.0078, 0.0118, 0.0118,  ..., 0.0235, 0.0235, 0.0235],\n         ...,\n         [0.0549, 0.0588, 0.0745,  ..., 0.0196, 0.0235, 0.0235],\n         [0.0039, 0.0078, 0.0078,  ..., 0.0000, 0.0039, 0.0039],\n         [0.0196, 0.0196, 0.0196,  ..., 0.0000, 0.0000, 0.0000]]]), 'Playing_violin')\n(tensor([[[0.2980, 0.3255, 0.3333,  ..., 0.1333, 0.0941, 0.0863],\n         [0.4039, 0.4157, 0.2078,  ..., 0.1333, 0.0941, 0.0863],\n         [0.4314, 0.2510, 0.1608,  ..., 0.1333, 0.0941, 0.0863],\n         ...,\n         [0.3020, 0.2980, 0.3098,  ..., 0.1255, 0.1255, 0.1255],\n         [0.3098, 0.3020, 0.3059,  ..., 0.1294, 0.1294, 0.1294],\n         [0.2941, 0.2863, 0.2980,  ..., 0.1294, 0.1294, 0.1294]],\n\n        [[0.3961, 0.4235, 0.4275,  ..., 0.1412, 0.1020, 0.0941],\n         [0.5020, 0.5098, 0.2980,  ..., 0.1412, 0.1020, 0.0941],\n         [0.5294, 0.3451, 0.2471,  ..., 0.1412, 0.1020, 0.0941],\n         ...,\n         [0.2980, 0.2941, 0.3059,  ..., 0.1255, 0.1255, 0.1255],\n         [0.3059, 0.2980, 0.3020,  ..., 0.1294, 0.1294, 0.1294],\n         [0.2902, 0.2824, 0.2980,  ..., 0.1294, 0.1294, 0.1294]],\n\n        [[0.1569, 0.1961, 0.2353,  ..., 0.0980, 0.0588, 0.0510],\n         [0.2745, 0.3020, 0.1176,  ..., 0.0980, 0.0588, 0.0510],\n         [0.3216, 0.1569, 0.0902,  ..., 0.0980, 0.0588, 0.0510],\n         ...,\n         [0.2902, 0.2863, 0.2980,  ..., 0.1333, 0.1333, 0.1333],\n         [0.2980, 0.2902, 0.2941,  ..., 0.1373, 0.1373, 0.1373],\n         [0.2824, 0.2745, 0.2863,  ..., 0.1373, 0.1373, 0.1373]]]), 'Deadlift')\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:48.250369Z","iopub.execute_input":"2023-10-19T13:56:48.250620Z","iopub.status.idle":"2023-10-19T13:56:48.415538Z","shell.execute_reply.started":"2023-10-19T13:56:48.250599Z","shell.execute_reply":"2023-10-19T13:56:48.414680Z"},"trusted":true},"execution_count":21,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e12413981b94652811066d9bfee02ac"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoImageProcessor, ViTModel\nimport torch\nfrom datasets import load_dataset\n\n\nimage_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224-in21k\")\nmodel = ViTModel.from_pretrained(\"google/vit-base-patch16-224-in21k\")","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:56:48.416543Z","iopub.execute_input":"2023-10-19T13:56:48.416758Z","iopub.status.idle":"2023-10-19T13:57:01.116826Z","shell.execute_reply.started":"2023-10-19T13:56:48.416738Z","shell.execute_reply":"2023-10-19T13:57:01.115863Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b06cb6bf231a491890636b019326d8f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8ba9a7b66ad465dbf78415c0c8b4d70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66e38ca6a4b4f0cbbe4fec7550ae22c"}},"metadata":{}}]},{"cell_type":"code","source":"custom_dataset","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.118082Z","iopub.execute_input":"2023-10-19T13:57:01.118610Z","iopub.status.idle":"2023-10-19T13:57:01.123910Z","shell.execute_reply.started":"2023-10-19T13:57:01.118585Z","shell.execute_reply":"2023-10-19T13:57:01.123093Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"<__main__.CustomDataset at 0x7b4e80a5a470>"},"metadata":{}}]},{"cell_type":"code","source":"# from transformers import TrainingArguments, Trainer\n# from sklearn.preprocessing import LabelEncoder\n# from sklearn.model_selection import train_test_split\n# import torch\n\n# images, labels = zip(*custom_dataset)\n\n# inputs = image_processor(images, return_tensors=\"pt\", padding=True,do_rescale=False)\n# label_encoder = LabelEncoder()\n# encoded_labels = label_encoder.fit_transform(labels)\n# encoded_labels = torch.tensor(encoded_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.124888Z","iopub.execute_input":"2023-10-19T13:57:01.125135Z","iopub.status.idle":"2023-10-19T13:57:01.557441Z","shell.execute_reply.started":"2023-10-19T13:57:01.125115Z","shell.execute_reply":"2023-10-19T13:57:01.556520Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# train_inputs, val_inputs, train_labels, val_labels = train_test_split(inputs[\"pixel_values\"], encoded_labels, test_size=0.1)\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.558640Z","iopub.execute_input":"2023-10-19T13:57:01.558918Z","iopub.status.idle":"2023-10-19T13:57:01.564963Z","shell.execute_reply.started":"2023-10-19T13:57:01.558895Z","shell.execute_reply":"2023-10-19T13:57:01.564165Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# training_args = TrainingArguments(\n#     per_device_train_batch_size=8,\n#     num_train_epochs=3,\n#     logging_dir='./logs',\n#     logging_steps=10,\n#     evaluation_strategy=\"steps\",\n#     eval_steps=50,\n#     save_steps=50,\n#     output_dir=\"./results\",\n# )\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.566302Z","iopub.execute_input":"2023-10-19T13:57:01.566879Z","iopub.status.idle":"2023-10-19T13:57:01.575832Z","shell.execute_reply.started":"2023-10-19T13:57:01.566848Z","shell.execute_reply":"2023-10-19T13:57:01.575032Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# def compute_accuracy(predictions, labels):\n#     _, predicted = torch.max(predictions, 1)\n#     total = labels.size(0)\n#     correct = (predicted == labels).sum().item()\n#     return correct / total","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.576818Z","iopub.execute_input":"2023-10-19T13:57:01.577222Z","iopub.status.idle":"2023-10-19T13:57:01.588200Z","shell.execute_reply.started":"2023-10-19T13:57:01.577186Z","shell.execute_reply":"2023-10-19T13:57:01.587570Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# from transformers import DefaultFlowCallback\n\n# trainer = Trainer(\n#     model=model,\n#     args=training_args,\n#     train_dataset=list(zip(train_inputs, train_labels)),\n#     eval_dataset=list(zip(val_inputs, val_labels)),\n#     compute_metrics=compute_accuracy,  # You can define your own metrics here\n# )\n\n# trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.591560Z","iopub.execute_input":"2023-10-19T13:57:01.591830Z","iopub.status.idle":"2023-10-19T13:57:01.600749Z","shell.execute_reply.started":"2023-10-19T13:57:01.591795Z","shell.execute_reply":"2023-10-19T13:57:01.599948Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(model.parameters(), lr=0.001)\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nnum_epochs = 5\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n\n    for inputs, labels in custom_dataset:\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        outputs = model(inputs)\n        loss = criterion(outputs.logits, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for inputs, labels in test_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs.logits, 1)\n\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] Loss: {running_loss / len(train_loader):.4f}, Accuracy: {accuracy:.4f}\")\n\nprint(\"Training complete.\")\n\n","metadata":{"execution":{"iopub.status.busy":"2023-10-19T13:57:01.601772Z","iopub.execute_input":"2023-10-19T13:57:01.601997Z","iopub.status.idle":"2023-10-19T13:57:01.612985Z","shell.execute_reply.started":"2023-10-19T13:57:01.601978Z","shell.execute_reply":"2023-10-19T13:57:01.612237Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Epoch [1/5] Loss: 0.1623, Accuracy: 0.8301\nEpoch [2/5] Loss: 0.0522, Accuracy: 0.7500\nEpoch [3/5] Loss: 0.0378, Accuracy: 0.6843\nEpoch [4/5] Loss: 0.0321, Accuracy: 0.8510\nEpoch [5/5] Loss: 0.0326, Accuracy: 0.7436\nTraining complete.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}